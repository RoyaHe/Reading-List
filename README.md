# Reading List
By [Roya He](https://royahe.github.io) (yunjie.he.17@ucl.ac.uk), this repository contains some informative papers and blogs on ML (Machine Learning) and NLP (Natural Language Processing). They are classified based on their themes. More interesting contents will be uploaded soon! Any recommendations are highly appreciated! 

### Knowledge Graphs
[Survey on Knowledge Graphs](https://github.com/RoyaHe/Reading-List/blob/main/file/Knowledge%20Graph.pdf)

[Multi-Modal Knowledge Graphs](https://arxiv.org/abs/1903.05485)

[K-BERT: Enabling Language Representation with Knowledge Graph](https://arxiv.org/pdf/1909.07606.pdf): fuse knowledge into the learned representation


### Multi-modal Learning
[Multimodal Intelligence: Representation Learning, Information Fusion, and Applications](https://arxiv.org/abs/1911.03977)

[Learning Grounded Meaning Representations with Autoencoders](https://aclanthology.org/P14-1068/)

[Blog: Multimodal Deep Learning](https://towardsdatascience.com/multimodal-deep-learning-ce7d1d994f4)

[MMRFAN: Multi-modal Multi-relational Feature Aggregation Network for Medical Knowledge Representation Learning](https://dl.acm.org/doi/abs/10.1145/3394171.3413736): maps entity's textual knowledge and visual knowledge into a unified space and learns representations.

[Integrating Image-Based and Knowledge-Based Representation Learning](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8689107): IKRL integrates image information and structured knowledge with TransE

[Representation Learning of Knowledge Graphs with Entity Descriptions](https://dl.acm.org/doi/10.5555/3016100.3016273): DKRL integrates textual information and structured knowledge with TransE


[A Multimodal Translation-Based Approach for Knowledge Graph Representation Learning](https://aclanthology.org/S18-2027/): combining complementary(multimodal) energies is found making the results more robust. Total plausibilities referring to structured KGs, visual and textual information.


### External Knowledge for Visual Question Answering
[Explicit Knowledge-based Reasoning for Visual Question Answering](https://www.ijcai.org/proceedings/2017/0179.pdf)

[FVQA: Fact-based Visual Question Answering](https://arxiv.org/pdf/1606.05433.pdf)

[Mucko: Multi-Layer Cross-Modal Knowledge Reasoning for Fact-based Visual](https://arxiv.org/pdf/2006.09073.pdf)

[Zero-shot Visual Question Answering using Knowledge Graphs](https://arxiv.org/pdf/2107.05348.pdfc)

[Multimodal Neural Graph Memory Networks for Visual Question Answering](https://aclanthology.org/2020.acl-main.643.pdf)



### Semi-supervised Learning and Adversarial Training
[Adversarial Training Methods for Semi-Supervised Text Classification](https://arxiv.org/abs/1605.07725)

[Blog: Introduction to semi-supervised learning and adversarial training](https://medium.com/inside-machine-learning/placeholder-3557ebb3d470)
